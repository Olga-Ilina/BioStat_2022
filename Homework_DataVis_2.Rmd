---
title: "Homework_Datavis_2"
author: "Olga"
date: "2022-10-23"
output: 
  html_document:
    keep_md: true
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
devtools::install_github("ropensci/plotly")
library(plotly)
```



```{r}
library(dplyr)
library(magrittr)
library(tidyr)
library(ggplot2)
library(ggpubr)
library(skimr)
library(tibble)
install.packages (c('dplyr', 'magrittr', 'tidyr', 'ggplot2', 'ggpubr', "skimr", "plotly", "tibble", 'fastDummies', "pheatmap", "FactoMineR",
"ggbiplot"), repos = "http://cran.us.r-project.org")
```

# 1. Загрузите датасет insurance_cost.csv.

```{r }
df <-read.csv ("insurance_cost.csv", stringsAsFactors = TRUE)

summary(df)
sum(is.na(df))
```
# 2. Сделайте интерактивный plotly график отношения индекса массы тела и трат на страховку. Раскрасьте его по колонке smoker
Plotly не всегда корректно ведёт себя во время knit – для него нужно настраивать .Rmd документ. Если вы столкнулись с тем, что у вас не-“нитится” из-за plotly – просто отмените выполнение чанка при сохранении кода в его настройках (eval=FALSE)

```{r}

pal <- c("#CC99FF", "#99CCFF")
pal <- setNames(pal, levels(df$smoker))

plot_ly(
  data = df, 
  x = ~bmi, 
  y = ~charges, 
  color = ~smoker,# Развивка по цвету по smoker
  text = ~charges,
  size = ~charges,
  hoverinfo = "text",
  colors = pal, alpha = 0.7, #Новая палетка и прозрачность
  marker = list(
    line = list(color = '#999999',  # Цвет окружности
                width = 1))) %>%
    layout(
    title = 'Отношение индекса массы тела и трат на страховку в зависимости от курения',
    yaxis = list(title = 'Индекс массы тела',
                 zeroline = FALSE), 
    xaxis = list(title = 'Траты на страховку',
                 zeroline = FALSE)) 

```


#3.Сделайте тоже самое через ggplotly
Plotly не всегда корректно ведёт себя во время knit – для него нужно настраивать .Rmd документ. Если вы столкнулись с тем, что у вас не-“нитится” из-за plotly – просто отмените выполнение чанка при сохранении кода в его настройках (eval=FALSE)

```{r}

plot <- df %>% 
  ggplot(aes(x=bmi, y=charges)) + 
  geom_point(color='#999999', shape=21, size=4, alpha = 0.7,
             aes(fill=factor(smoker))) + 
  scale_fill_manual(values=c('#CC99FF', '#99CCFF')) +
  xlab("BMI") + 
  ylab("Charges") +
  theme_light()+
  theme(plot.title = element_text(size = 14, hjust = 0.5),
        axis.text.x = element_text(size = 14))

ggplotly(plot)


```


#4.Кратко сделайте корреляционный анализ данных insurance_cost. Посмотрите документацию пакетов, которые мы проходили на занятии и, исходя из этого,постройте минимум два новых типа графика (которые мы не строили на занятии).
```{r}
library(corrplot)
```
```{r}
# Удаляем ошибочные значения
df_clear <- df %>% 
  filter(children != 0 & charges != 0) %>% 
  select(is.integer | is.numeric) 

head(df_clear)
```

```{r}
df_cor <- cor(df_clear)
df_cor
```


```{r}
corrplot(df_cor, method = 'circle', order = 'alphabet')
```
```{r}
corrplot(df_cor, method = 'pie')
```



```{r}
corrplot(df_cor, method = 'square', order = 'FPC', type = 'lower', diag = FALSE)
```
```{r}
corrplot(df_cor, method = 'square', diag = FALSE, order = 'hclust',
         addrect = 3, rect.col = 'blue', rect.lwd = 3, tl.pos = 'd')
```

Наибольшая корреляция отмечается между charges и age, charges и bmi



```{r}
library(magrittr)


df_aggr <- df %>% 
  group_by(smoker, sex) %>% 
  summarise(N = n())


```

```{r}
df_aggr %>% 
  ggplot(aes(x = smoker, y = sex, fill = N)) +
  geom_tile(color = "black") +
  geom_text(aes(label = N), color = "white", size = 4) +
  coord_fixed()
```


#5.Превратите все номинативные переменные в бинарные/дамми. Т.е. sex и smoker должны стать бинарными (1/0), а каждое уникальное значение region – отдельной колонкой, где 1 говорит о наличии этого признака для наблюдения, а 0 – об отсутствии (В работе с данными эта операция называется one hot-encoding). Создайте новый датафрейм, где вы оставите только нумерические переменные.

```{r}
str(df)
```


```{r}
# создадим dummy variables
# из переменых sex и smoker с помощью функции mutate (case_when), из переменной region с помощью функции dummy_cols

library('fastDummies')

df_numeric <- df %>%
mutate(sex_cat = case_when(
  sex == 'female' ~0,
  sex == 'male' ~ 1
)) %>%
mutate(smoker_cat = case_when(
  smoker == 'no' ~ 0,
  smoker == 'yes' ~ 1
)) %>%
 dummy_cols(select_columns = 'region') %>%
  select(is.integer | is.numeric)

head(df_numeric)


```




#6.Постройте иерархическую кластеризацию на этом датафрейме

```{r}
library(factoextra)
library(magrittr)
library(dplyr)

```

```{r}
# Получаем объект матрицы. Избавляемся от ошибочных значений
new_df_clear <- df_numeric %>% 
  filter(age != 0 & bmi != 0 & charges != 0) 

head(new_df_clear)
```

```{r}
# Стандартизуем значения
new_df_clear_scaled <- scale(new_df_clear)
```

```{r}
# Создаём матрицу дистанций по методу Euclidian
new_df_clear_dist <- dist(new_df_clear_scaled, method = "euclidean")
as.matrix(new_df_clear_dist)[1:8,1:8]
```


```{r}
# Создаем дендрограмму кластера
new_df_clear_hc <- hclust(d = new_df_clear_dist, 
                        method = "ward.D2")
```

 
```{r}
# Визуализируем
fviz_dend(new_df_clear_hc, 
          cex = 0.1, # cex() - размер лейблов
          main = "Dendrogram", # Название
          xlab = "Objects",
          ylab = "Distance")
```

```{r}
# Verify the cluster tree
new_df_clear_coph <-cophenetic(new_df_clear_hc) # compute cophenetic distance
cor (new_df_clear_dist, new_df_clear_coph ) # correlation between cophenetic distance and the original distance. Correlation coefficient 0.729 for a strong correlantion
```

#7.(это задание засчитывается за два) Используя документацию или предложенный учебник (С. 64-117)сделайте ещё несколько возможных графиков по иерархической кластеризации. Попробуйте раскрасить кластеры разными цветами (с. 75)

```{r}
fviz_dend(new_df_clear_hc, k = 5,
          cex = 0.5,
          k_colors = "jco",
          color_labels_by_k = TRUE, 
          rect = TRUE, 
          rect_border = "jco",
          rect_fill = TRUE)
      
```




```{r}
df_grp <- cutree(new_df_clear_hc, k = 4)

table (df_grp)

fviz_cluster(list(data = new_df_clear_dist, cluster = df_grp),
  ellipse.type = "convex", 
  repel = TRUE,
  show.clust.cent = FALSE, 
  ggtheme = theme_minimal())

```

```{r}
# Если взять другой метод вычисления дистанций  - например, manhattan

# Создаём матрицу дистанций по методу Manhattan
df_dist_m <- dist(new_df_clear_scaled, method = "manhattan")
as.matrix(df_dist_m)[1:8,1:8]

# Создаем дендрограмму кластера с помощью метода "median"
df_hc_complete <- hclust(d = new_df_clear_dist, 
                        method = "median")

df_grp_2 <- cutree(df_hc_complete, k = 4)

table(df_grp_2)

fviz_cluster(list(data = df_dist_m, cluster = df_grp_2),
  ellipse.type = "convex", 
  repel = TRUE,
  show.clust.cent = FALSE, ggtheme = theme_minimal())


```
Результаты кластерного анализа будут отличаться при использовании разных методов определения дистанций и постооения дендрограммы.

```{r}
# Из первого датафрейма создадим датафрейм из наиболее коррелирующих переменных: age, charges, bmi

df_new <- df_numeric %>% 
  select('charges', 'age', 'bmi')

df_new_clear <- df_new %>% 
  filter(age != 0 & bmi != 0 & charges != 0) 

df_new_clear_scaled <- scale(df_new_clear)

df_new_clear_dist <- dist(df_new_clear_scaled, method = "euclidean")
as.matrix(new_df_clear_dist)[1:8,1:8]

df_new_clear_hc <- hclust(d = df_new_clear_dist, 
                        method = "ward.D2")

fviz_dend(new_df_clear_hc, k = 5, 
  cex = 0.1,
  horiz = TRUE,
  k_colors = "jco",
          color_labels_by_k = TRUE, 
          rect = TRUE, 
          rect_border = "jco",
          rect_fill = TRUE,
          ggtheme = theme_gray())

```

```{r}
# Zooming the dendrogram
fviz_dend(df_new_clear_hc, xlim = c(1, 200), ylim = c(1, 20))
```



#Circular dendrogram
```{r}
fviz_dend(df_new_clear_hc, cex = 0.5, k = 4,
          k_colors = 'jco', type = "circular" )
```


#8. Сделайте одновременный график heatmap и иерархической кластеризации

```{r}
library(pheatmap)
```

```{r}
pheatmap(new_df_clear_scaled)
```



#9.Проведите анализ данных полученных в задании 5 методом PCA. Кратко проинтерпретируйте полученные результаты.

```{r}
library(FactoMineR)
library(ggbiplot)
```


```{r}
df_pca <- prcomp(df_numeric,
                        scale = T)
summary(df_pca)

fviz_eig(df_pca, 
         addlabels = T, 
         ylim = c(0, 40))

# Первые 4 компоненты объясняют 60.6% вариации данных. 7 первых компонент объясняют 90.9% вариации данных
```


```{r}
fviz_pca_var(df_pca, col.var = "contrib")

#На графике выделяются 3 группы переменных: 1) region_southeast, bmi; 2) charges, smokers_cat; age; 3) остальные. Отрицательно скоррелированы region_southeast, bmi и region_nothwest, region_northwest

```





```{r}
fviz_pca_var(df_pca, 
             select.var = list(contrib = 5), # Число компонент  
             col.var = "contrib")
```

```{r}
fviz_contrib(df_pca, choice = "var", axes = 1, top = 24) 
# 1 компонента - charges & smoker

```

```{r}
fviz_contrib(df_pca, choice = "var", axes = 2, top = 24) 
# 2 компонента - region southeast, region northeast и bmi
```

```{r}
fviz_contrib(df_pca, choice = "var", axes = 3, top = 24) 
# 3 компонента - region southwest

```

```{r}
fviz_contrib(df_pca, choice = "var", axes = 4, top = 24) 
# 4 компонента - region norhtwest & region northeast

```

```{r}
fviz_contrib(df_pca, choice = "var", axes = 5, top = 24) 
# 5 компонента - age
```

```{r}
ggbiplot(df_pca, 
         scale=0, alpha = 0.1) + 
  theme_minimal()

#PC1 объясняет 19.4% вариации, PC2 14.8%
```

```{r}
#PC1 объясняет 19.4% дисперсии. В PC1 входят charges и smoker. PC2 объясняет 14.8% дисперсии. В PC2 входят region и bmi.
```


#10.В финале вы получите график PCA по наблюдениям и переменным. Сделайте кластеризацию (В значении кода на строке 909 файла R_pro_work_with_graphics.Rmd) данных на нём по возрастным группам (создайте их сами на ваш вкус, но их количество должно быть не меньше 3).
```{r}
# Создадим категориальную переменную по возрасту 
df_2 <-df_numeric %>%
  mutate(age_group = case_when(age < 40 ~ "1",
                               age >= 40 & age < 60 ~ "2",
                               age >= 60 ~ "3")) 

ggbiplot(df_pca, 
         scale=0, 
         groups = as.factor(df_2$age_group), 
         ellipse = T,
         alpha = 0.2) +
  theme_minimal()
```


#11. Подумайте и создайте ещё две номинативные переменные, которые бы гипотетически могли хорошо разбить данные на кластеры. Сделайте две соответствующие визуализации.

```{r}
#Создадим переменную Obesity

df_2 <-df_2 %>%
  mutate(bmi_group = case_when(bmi < 35 ~ "0",
                               bmi >= 35 ~ "1")) 

df_2$bmi_group <- factor(df_2$bmi_group, labels = c("No obesity", "Obesity"))

ggbiplot(df_pca, 
         scale=0, 
         groups = df_2$bmi_group, 
         ellipse = T,
         alpha = 0.2) +
  theme_minimal()
```



```{r}
#Создадим переменную Charges 
df_2 <-df_2 %>%
  mutate(charges_group = case_when(charges< 20000 ~ "0",
                               charges >= 20000 ~ "1"))
df_2$charges_group <- factor(df_2$charges_group, labels = c("< 20000", ">= 20000"))

ggbiplot(df_pca, 
         scale=0, 
         groups = df_2$charges_group, 
         ellipse = T,
         alpha = 0.2) +
  theme_minimal()
```


#12. (это задание засчитывается за три) Давайте самостоятельно увидим, что снижение размерности – это группа методов, славящаяся своей неустойчивостью. Попробуйте самостоятельно поизменять дафрейм – удалить какие-либо переменные или создать их (создавайте только дамми переменные). Ваша задача –резко поднять качество вашего анализа PCA (при этом, фактически, оперируя всё теми же данными). Кратко опишите, почему добавление той или иной дамми-переменной так улучшает PCA.
```{r}
str(df_numeric)
```

```{r}
# Дамми-переменные - region, sex, smoker. Удалим по очереди эти переменные
# Удалим region

df_pca_r <- df_numeric %>%
  select(-contains("region_")) %>%
  prcomp(
          scale = T) 
  
df_pca1 <- fviz_eig(df_pca_r,
         addlabels = T, 
         ylim = c(0, 40))

df_pca1
```

```{r}
# Удалим smoker
df_pca_sm <- df_numeric %>%
  select(-contains("smoker")) %>%
  prcomp(
          scale = T) 
  
df_pca2 <- fviz_eig(df_pca_sm,
         addlabels = T, 
         ylim = c(0, 40))

df_pca2
```

```{r}
# Удалим sex
df_pca_sex <- df_numeric %>%
  select(-contains("sex")) %>%
  prcomp(
          scale = T) 
  
df_pca3 <- fviz_eig(df_pca_sex,
         addlabels = T, 
         ylim = c(0, 40))

df_pca3
```
```{r}
#При удалении переменной regions качество модели повышается. При этом выяввляется ведущая компонента, которая объясняет 31.4% дисперсии
```

```{r}
# Добавим дамми-переменные age_group и bmi_group после удаления переменной region

#Удалим переменную region
df_pca_region <- df_numeric %>%
  select(-contains("region_"))

# Добавим дамми-переменную bmi_group
df_pca4 <-df_pca_region %>%
  mutate(bmi_group = case_when(bmi < 35 ~ "0",
                               bmi >= 35 ~ "1")) 

df_pca4$bmi_group <- as.numeric(as.character(df_pca4$bmi_group))

pca4 <- prcomp(df_pca4,
                        scale = T)

fviz_eig(pca4, 
         addlabels = T, 
         ylim = c(0, 40))

```

После удаления переменной region и добавления переменной bmi_group  качество модели повышается и выделяется ведущая компонента, которая объясняет 29.3% дисперсии.

```{r}

# Добавим дамми-переменную age_group после удаления переменной region
df_pca5 <-df_pca_region %>%
  mutate(age_group = case_when(age < 40 ~ "1",
                               age >= 40 & age < 60 ~ "2",
                               age >= 60 ~ "3"))

df_pca5$age_group <- as.numeric(as.character(df_pca5$age_group))

pca5 <- prcomp(df_pca5,
                        scale = T)

fviz_eig(pca5, 
         addlabels = T, 
         ylim = c(0, 40))
```

После удаления переменной region и добавления переменной age_group  качество модели резко повышается и выделяется ведущая компонента, которая объясняет 31.4% дисперсии

```{r}
# Добавим дамми-переменные age_group и bmi_group после удаления переменной region
df_pca6 <-df_pca_region %>%
  mutate(age_group = case_when(age < 40 ~ "1",
                               age >= 40 & age < 60 ~ "2",
                               age >= 60 ~ "3")) %>%
  mutate(bmi_group = case_when(bmi < 35 ~ "0",
                               bmi >= 35 ~ "1")) 

df_pca6$age_group <- as.numeric(as.character(df_pca6$age_group))
df_pca6$bmi_group <- as.numeric(as.character(df_pca6$bmi_group))

pca6 <- prcomp(df_pca6,
                        scale = T)

fviz_eig(pca6, 
         addlabels = T, 
         ylim = c(0, 40))
```
При добавлении дамми-переменных age_group и bmi_group после удаления переменной region качество модели меняется незначительно по сравнению только с переменной bmi. Наилучшую модель мы получаем после удаления переменной region и добавлении переменной age_group.


